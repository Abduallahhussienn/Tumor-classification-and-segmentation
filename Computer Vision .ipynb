{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db1e3395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "#!pip install imutils\n",
    "import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import random\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from sklearn.utils import shuffle           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37940513",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_path='Dataset\\Dataset\\Brain scans'\n",
    "breast_path='Dataset\\Dataset\\Breast scans'\n",
    "brain_label=0\n",
    "breast_label=1\n",
    "#VGG\n",
    "Image_Width=224\n",
    "Image_height=224"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5837e18",
   "metadata": {},
   "source": [
    "Labelling Breast or Brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4da22738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder,i):\n",
    "    images = []\n",
    "    labels=[]\n",
    "\n",
    "    for filename in os.listdir(folder):\n",
    "        #print(filename)\n",
    "        if \"_mask\" not in filename :\n",
    "            #print(filename)\n",
    "            img = cv2.imread(os.path.join(folder,filename))\n",
    "        #         img = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n",
    "        #         img = cv2.erode(thresh, None, iterations=2)\n",
    "            #img = preprocess_input(img)\n",
    "            img = cv2.dilate(img, None, iterations=2)\n",
    "            img = cv2.resize(img, (Image_Width, Image_height))\n",
    "            \n",
    "\n",
    "            if img is not None:\n",
    "                images.append(img)\n",
    "                labels.append(i)\n",
    "                \n",
    "    images = np.array(images, dtype = 'float32')\n",
    "    labels = np.array(labels, dtype = 'int32')   \n",
    "\n",
    "  \n",
    "    return images,labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c416f5a4",
   "metadata": {},
   "source": [
    "Brain Reading File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee6115c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inner path ['No tumor', 'Tumor']\n",
      "Dataset\\Dataset\\Brain scans\\No tumor\\Test\n",
      "Dataset\\Dataset\\Brain scans\\No tumor\\Train\n",
      "Dataset\\Dataset\\Brain scans\\Tumor\\TEST\n",
      "Dataset\\Dataset\\Brain scans\\Tumor\\TRAIN\n"
     ]
    }
   ],
   "source": [
    "inner=os.listdir(brain_path)\n",
    "print(\"inner path\",inner)\n",
    "#k:no tumor or tumor\n",
    "#n:train/test\n",
    "for k in inner:\n",
    "    \n",
    "#print(k)\n",
    "    train_test=os.listdir(os.path.join(brain_path,k))\n",
    "    for n in train_test:\n",
    "        if n=='Train'or n=='TRAIN':\n",
    "        #print('n',n)\n",
    "            folder=os.path.join(brain_path,k,n)\n",
    "            print(folder)\n",
    "\n",
    "            brain_images_Train,brain_labels_Train=load_images_from_folder(folder,brain_label)\n",
    "        elif n=='Test'or n=='TEST':\n",
    "            folder=os.path.join(brain_path,k,n)\n",
    "            print(folder)\n",
    "\n",
    "            brain_images_Test,brain_labels_Test=load_images_from_folder(folder,brain_label)\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c200f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0656b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# brain_images_Train=np.asarray(brain_images_Train).astype('float32')\n",
    "# brain_images_Train[5][1]\n",
    "# breast_images_Train=np.asarray(breast_images_Train).astype('float32')\n",
    "# breast_images_Train[5][1]\n",
    "# Training_Data=np.concatenate((brain_images_Train,breast_images_Train),axis=0)\n",
    "# Testing_Data=np.concatenate((brain_images_Test,breast_images_Test),axis=0)\n",
    "# random.shuffle(Training_Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b0e35d",
   "metadata": {},
   "source": [
    "Breast Reading File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d05262ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inner path ['benign', 'malignant', 'normal']\n",
      "benign\n",
      "n Test\n",
      "n Train\n",
      "malignant\n",
      "n Test\n",
      "n Train\n",
      "normal\n",
      "n Test\n",
      "n Train\n"
     ]
    }
   ],
   "source": [
    "inner=os.listdir(breast_path)\n",
    "print(\"inner path\",inner)\n",
    "#k:no tumor or tumor\n",
    "#n:train/test\n",
    "for k in inner:\n",
    "    print(k)\n",
    "    train_test=os.listdir(os.path.join(breast_path,k))\n",
    "    for n in train_test:\n",
    "        if n=='Train':\n",
    "            print('n',n)\n",
    "            folder=os.path.join(breast_path,k,n)\n",
    "#         for filename in os.listdir(os.path.join(brain_path,k,n)):\n",
    "#             print(filename)\n",
    "#             img = cv2.imread(os.path.join(os.path.join(brain_path,k,n),filename))\n",
    "            breast_images_Train,breast_labels_Train=load_images_from_folder(folder,breast_label)\n",
    "        elif n=='Test':\n",
    "            print('n',n)\n",
    "            folder=os.path.join(breast_path,k,n)\n",
    "#         for filename in os.listdir(os.path.join(brain_path,k,n)):\n",
    "#             print(filename)\n",
    "#             img = cv2.imread(os.path.join(os.path.join(brain_path,k,n),filename))\n",
    "            breast_images_Test,breast_labels_Test=load_images_from_folder(folder,breast_label)\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d39aa2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_Data=np.concatenate((brain_images_Train,breast_images_Train),axis=0)\n",
    "Test_Data=np.concatenate((brain_images_Test,breast_images_Test),axis=0)\n",
    "Training_Data_Label=np.concatenate((brain_labels_Train,breast_labels_Train),axis=0).reshape((-1,1))\n",
    "Testing_Data_Label=np.concatenate((brain_labels_Test,breast_labels_Test),axis=0).reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5473a97c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(603, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Training_Data_Label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ba1c1ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(603, 224, 224, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Training_Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ae64ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_Data, Training_Data_Label = shuffle(Training_Data, Training_Data_Label, random_state=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ddf6d8",
   "metadata": {},
   "source": [
    "Labelling Tumor or No Tumor / Malignant Or begnin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "586117a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We Can USE THEM FOR LABELLING INNER CLASS\n",
    "#Do not run not implemented yet\n",
    "\n",
    "def load_data():\n",
    "    output = []\n",
    "    \n",
    "    # Iterate through training and test sets\n",
    "    for dataset in datasets:\n",
    "        \n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        print(\"Loading {}\".format(dataset))\n",
    "        \n",
    "        # Iterate through each folder corresponding to a category\n",
    "        for folder in os.listdir(dataset):\n",
    "            label = class_names_label[folder]\n",
    "            \n",
    "            # Iterate through each image in our folder\n",
    "            for file in tqdm(os.listdir(os.path.join(dataset, folder))):\n",
    "                \n",
    "                # Get the path name of the image\n",
    "                img_path = os.path.join(os.path.join(dataset, folder), file)\n",
    "                \n",
    "                # Open and resize the img\n",
    "                image = cv2.imread(img_path)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                image = cv2.resize(image, IMAGE_SIZE) \n",
    "                \n",
    "                # Append the image and its corresponding label to the output\n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "                \n",
    "        images = np.asarray(images, dtype = 'float32')\n",
    "        labels = np.asarray(labels, dtype = 'int32')   \n",
    "        \n",
    "        output.append((images, labels))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b1a945",
   "metadata": {},
   "source": [
    "VGG Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a1ff253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D\n",
    "from keras.layers import MaxPool2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6569c251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 112, 112, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 56, 56, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 28, 28, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 14, 14, 512)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " vgg16 (MaxPooling2D)        (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " output (Dense)              (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,264,641\n",
      "Trainable params: 134,264,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "# model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "# model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "# model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "# model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "# model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "# model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "# model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "# model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "# model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "# model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "# model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "# model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "# model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "# model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "# model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "# model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "# model.add(MaxPool2D(pool_size=(2,2),strides=(2,2),name='vgg16'))\n",
    "# model.add(Flatten(name='flatten'))\n",
    "# model.add(Dense(4096, activation='relu', name='fc1'))#256\n",
    "# model.add(Dense(4096, activation='relu', name='fc2'))#128\n",
    "# model.add(Dense(1, activation='softmax', name='output'))#2 classes\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b80bcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG19 ARCITECHTURE\n",
    "\n",
    "# from keras.applications.vgg16 import VGG16\n",
    "# model = VGG16()\n",
    "# print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98cccb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "#hist = model.fit(Training_Data,batch_size=128, epochs=20, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e33cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "# from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "# checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "# early = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\n",
    "# hist = model.fit(Training_Data,Training_Data_Label,batch_size=128, epochs=20, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07246a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_4\n",
      "block1_conv1\n",
      "block1_conv2\n",
      "block1_pool\n",
      "block2_conv1\n",
      "block2_conv2\n",
      "block2_pool\n",
      "block3_conv1\n",
      "block3_conv2\n",
      "block3_conv3\n",
      "block3_pool\n",
      "block4_conv1\n",
      "block4_conv2\n",
      "block4_conv3\n",
      "block4_pool\n",
      "block5_conv1\n",
      "block5_conv2\n",
      "block5_conv3\n",
      "block5_pool\n"
     ]
    }
   ],
   "source": [
    "pre_trained_model = tf.keras.applications.VGG16(input_shape=(224, 224, 3), include_top=False, weights=\"imagenet\")\n",
    "for layer in pre_trained_model.layers:\n",
    "    print(layer.name)\n",
    "    layer.trainable = False\n",
    "last_layer = pre_trained_model.get_layer('block5_pool')\n",
    "last_output = last_layer.output\n",
    "x = tf.keras.layers.GlobalMaxPooling2D()(last_output)\n",
    "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "model = tf.keras.Model(pre_trained_model.input, x)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3d00242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "27/27 [==============================] - 85s 3s/step - loss: 1.9734 - acc: 0.9481 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 94s 3s/step - loss: 0.0535 - acc: 0.9979 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 92s 3s/step - loss: 0.0022 - acc: 0.9979 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 94s 3s/step - loss: 7.0606e-35 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 90s 3s/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(Training_Data,Training_Data_Label,batch_size=18, epochs=5, validation_split = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b960cc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 19s 4s/step\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "predictions = model.predict(Test_Data)\n",
    "print(predictions)\n",
    "accuracy = accuracy_score(Testing_Data_Label, predictions)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f02c4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Testing_Data_Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da95c38b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
